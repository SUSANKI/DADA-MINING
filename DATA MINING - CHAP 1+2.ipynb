{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRODUCTION - DATA MINING PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINITION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* THE USE OF EFFICIENT TECHNIQUES FOR THE ANALYSIS OF LARGE COLLECTION OF DATA\n",
    "* EXTRACTION OF USEFUL AND POSSIBLY UNEXPECTED PATTERNS IN DATA COLLECTED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ANALYSIS OF OBSERVATIONAL DATA SETS TO FIND UNSUSPECTED RELATIONSHIPS AND TO SUMMARIZE THE DATA IN THE NOVEL WAY WHICH IS UNDERSTANDABLE AND USEFUL.\n",
    "* MODELS OF DATA:\n",
    "    * EXPLAIN THE DATA\n",
    "    * PREDICT THE FUTURE DATA INSTANCE\n",
    "    * SUMMARIZE THE DATA\n",
    "    * EXTRACT THE MOST SIGNIFICANT FEATURES OF DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SOME ANALYTICS APPROACH\n",
    "  * DESCRITIVE STATISTICS: TELLS US WHAT HAPPENED IN THE PAST\n",
    "  * DIAGNOSIC STATISTICS: UNDERSTAND WHY SOME EVENTS HAPPEN\n",
    "  * PREDICTIVE STATISTICS: PREDICT WHICH EVENTS ARE MOST LIELY TO OCCUR IN THE FUTURE\n",
    "  * PRESCRIPTIVE STATISTIC: RECOMMEND ACTIONS TO ACHIEVE PARTICULAR OUTCOMES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WHY DATA MINING?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* EXTREMELY LARGE AMOUNT OF DATA AND CHEAP STORAGE ENABLE FOR MAINTAINING THESE DATA\n",
    "* USED TO EXTRACT NEW KNOWLEDGE\n",
    "* DATA IS POWER\n",
    "* A WAY TO HARNESS COLLECTIVE INTELLIGENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA COMPLEXITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MULTIPLE TYPE: TABLES, TIME SERIES, IMAGES, GRAPHS, RECORDS, VIDEOS,...\n",
    "* SPACIAL (DIMENSION) AND TEMPORAL (TIME)\n",
    "* INTERCONNECTED DATA (ex: a person: location, voice, height, check-in venues,...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Transaction data,Stock price and return data, Doument data, Network data, Geometric sequences (ex:gene, medical record), Environmental data, Behavioral data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA DEFINITION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* COLLECTION OF DATA \"OBJECTS\" AND \"ATTRIBUTES\"\n",
    "* ATTRIBUTE: PROTERTIES OR CHARACTERISTICS OF OBJECTS. A COLLECTION OF ATTRIBUTES DESCRIBE AN OBJECT\n",
    "* OBJECT:    NUMBER, WORD, MEASUREMENT, OBSERVATION OR DESCRIPTION OF THING(S), CAN BE QUALITATIVE OR QUANTITATIVE (NUMERIC OR CATEGORICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SIZE:    NUMBER OF OBJECTS\n",
    "* DIMENSIONALITY: NUMBER OF ATTRIBUTES\n",
    "* SPARSITY: NUMBER OF POPULATED OBJECT-ATTRIBUTE PAIRS\n",
    "* (Note: Sparsity and Density, If data is meaningful / useful / not random, you will have regions where data points come together and cluster, and you will have areas they avoid coming together.Data Scientists will look for ways to maximize sparsity so that they can get good clusters or well defined answers to their questions.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ATTRIBUTE      | OBJECT          |\n",
      "|----------------+-----------------|\n",
      "| VARIABLE       | RECORD          |\n",
      "| FIELD          | POINT/CASE      |\n",
      "| CHARACTERSITIC | SAMPLE          |\n",
      "| FEATURE        | ENTITY/INSTANCE |\n"
     ]
    }
   ],
   "source": [
    "# There are several ways of calling:\n",
    "from tabulate import tabulate\n",
    "l = [[\"VARIABLE\", \"RECORD\"],[\"FIELD\", \"POINT/CASE\"],[\"CHARACTERSITIC\", \"SAMPLE\"] ,[\"FEATURE\", \"ENTITY/INSTANCE\"]]\n",
    "table = tabulate(l, headers=['ATTRIBUTE', 'OBJECT'], tablefmt='orgtbl')\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATTRIBUTES TYPES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* CATEGORICAL DATA (QUALITATIVE)\n",
    "  * NOMINAL DATA: No order or comparison, multually exclusive (ex: make/female)\n",
    "  * ORDINAL DATA: order but not comparable,multually exclusive(ex: student's ID)\n",
    "\n",
    "*NUMERIC DATA (QUANTITATIVE)\n",
    "  * DISCRETE DATA: numerical values, finite or countably infinite (ex: number of student)                                                             \n",
    "  * CONTINUOUS DATA: Real value numbers, can take any value within a range (ex: Temperature)\n",
    "                                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MsCode</th>\n",
       "      <th>DemCode</th>\n",
       "      <th>EstCode</th>\n",
       "      <th>Year</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>SE</th>\n",
       "      <th>LowerCIB</th>\n",
       "      <th>UpperCIB</th>\n",
       "      <th>Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MEASA</td>\n",
       "      <td>ETHG01</td>\n",
       "      <td>A_Proportion</td>\n",
       "      <td>2019</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "      <td>8.7</td>\n",
       "      <td>10.8</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MEASA</td>\n",
       "      <td>ETHG01</td>\n",
       "      <td>B_Number</td>\n",
       "      <td>2019</td>\n",
       "      <td>71.3</td>\n",
       "      <td>8.2</td>\n",
       "      <td>63.2</td>\n",
       "      <td>79.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MEASA</td>\n",
       "      <td>ETHG01</td>\n",
       "      <td>C_Population</td>\n",
       "      <td>2019</td>\n",
       "      <td>731.3</td>\n",
       "      <td>19.6</td>\n",
       "      <td>711.7</td>\n",
       "      <td>751</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MEASA</td>\n",
       "      <td>ETHG01</td>\n",
       "      <td>D_Proportion_diff</td>\n",
       "      <td>2019</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MEASA</td>\n",
       "      <td>ETHG01</td>\n",
       "      <td>E_Number_diff</td>\n",
       "      <td>2019</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  MsCode DemCode            EstCode  Year Estimate    SE LowerCIB UpperCIB  \\\n",
       "0  MEASA  ETHG01       A_Proportion  2019      9.8     1      8.7     10.8   \n",
       "1  MEASA  ETHG01           B_Number  2019     71.3   8.2     63.2     79.5   \n",
       "2  MEASA  ETHG01       C_Population  2019    731.3  19.6    711.7      751   \n",
       "3  MEASA  ETHG01  D_Proportion_diff  2019                                    \n",
       "4  MEASA  ETHG01      E_Number_diff  2019                                    \n",
       "\n",
       "   Flag  \n",
       "0   3.0  \n",
       "1   2.0  \n",
       "2   4.0  \n",
       "3   7.0  \n",
       "4   1.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "data= pd.read_csv(\"C:/Users/Win 10/Downloads/cp-reg-eth-dis-datafile-csv.csv\")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOMINAL DATA: EstCode\n",
    "# ORDINAL DATA: MsCode, DemCode\n",
    "# DISCRETE DATA: Flag\n",
    "# CONTINUOUS DATA: Estimate, SE, LowerCIB, UpperCIB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NUMERIC RECORD DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* DATA HAVE THE SAME FIXED SET OF NUMERIC VARIABLES\n",
    "* WE CAN CONSIDER EACH INSTANCE AS A POINT IN D-DIMENSIONAL SPACE (D: NUMBER OF ATTRIBUTES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>22.5</td>\n",
       "      <td>72.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>46.5</td>\n",
       "      <td>72.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>27.5</td>\n",
       "      <td>86.5</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>51.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>55.5</td>\n",
       "      <td>93.5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>95.0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>31.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>33.5</td>\n",
       "      <td>47.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>57.5</td>\n",
       "      <td>92.5</td>\n",
       "      <td>34.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>75.5</td>\n",
       "      <td>20.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>44.5</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>83.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>67.5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>50.5</td>\n",
       "      <td>22.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>86.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>50.0</td>\n",
       "      <td>91.5</td>\n",
       "      <td>92.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>66.5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>63.5</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>95.5</td>\n",
       "      <td>28.5</td>\n",
       "      <td>99.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>51.5</td>\n",
       "      <td>77.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>97.5</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>75.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>10.5</td>\n",
       "      <td>39.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>57.5</td>\n",
       "      <td>74.5</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    C1    C2    C3    C4    C5    C6    C7    C8     C9   C10\n",
       "0           1  22.5  72.0   7.0  46.5  72.0   3.0  10.5  27.5   86.5  58.0\n",
       "1           2   3.0  48.0  51.5   5.0  36.0  11.5  55.5  93.5   22.0  11.5\n",
       "2           3  95.0  34.5   4.5  31.0  26.0  45.0  33.5  47.5   15.0   4.0\n",
       "3           4  57.5  92.5  34.0  82.0  86.0  75.5  20.5   2.0   44.5  14.0\n",
       "4           5  83.0  49.0  33.0  86.0  93.0  98.0  65.0  87.0   16.5  95.0\n",
       "5           6   2.0  67.5  22.0  50.5  22.5   7.0  29.0  22.5  100.0  86.5\n",
       "6           7  50.0  91.5  92.5  14.0  54.0   3.5  66.5  21.0   14.0   9.5\n",
       "7           8  63.5  17.0  14.0  95.5  28.5  99.0  58.0  77.0   20.5  59.0\n",
       "8           9  51.5  77.0  29.0  47.0  48.0  68.0  93.0  16.0   97.5  76.0\n",
       "9          10  75.0  91.0   4.5  10.5  39.0  82.5  12.0  57.5   74.5  11.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_numeric=pd.read_csv(\"C:/Users/Win 10/Documents/TABLE.csv\")\n",
    "data_numeric.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CATEGORICAL DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* EACH RECORD CONTAINS FIXED SET OF CATEGORICAL ATTRIBUTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>poor</td>\n",
       "      <td>Hoang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>medium</td>\n",
       "      <td>Phung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>rich</td>\n",
       "      <td>Giang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>Hoang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>poor</td>\n",
       "      <td>Phung</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   V1      V2     V3\n",
       "0           1   No    poor  Hoang\n",
       "1           2   No  medium  Phung\n",
       "2           3  Yes    rich  Giang\n",
       "3           4  Yes    poor  Hoang\n",
       "4           5  Yes    poor  Phung"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_categorical=pd.read_csv(\"C:/Users/Win 10/Documents/TABLE_2.csv\")\n",
    "data_categorical.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOCUMENT DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* EACH DOCUMENT IS A \"TERM\" VECTOR, EACH ATTRIBUTE IS A TERM EXISTING IN DOCUMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRANSACTION (SET) DATA\n",
    "* EACH TRANSACTION (INSTANCE) CONTAINS A SET OF ITEMS (EACH ITEM CAN BE REPRESENTED AS BINARY DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Invoice ID</th>\n",
       "      <th>Branch</th>\n",
       "      <th>City</th>\n",
       "      <th>Customer type</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Product line</th>\n",
       "      <th>Unit price</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Tax 5%</th>\n",
       "      <th>Total</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Payment</th>\n",
       "      <th>cogs</th>\n",
       "      <th>gross margin percentage</th>\n",
       "      <th>gross income</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>750-67-8428</td>\n",
       "      <td>A</td>\n",
       "      <td>Yangon</td>\n",
       "      <td>Member</td>\n",
       "      <td>Female</td>\n",
       "      <td>Health and beauty</td>\n",
       "      <td>74.69</td>\n",
       "      <td>7</td>\n",
       "      <td>26.1415</td>\n",
       "      <td>548.9715</td>\n",
       "      <td>1/5/2019</td>\n",
       "      <td>13:08</td>\n",
       "      <td>Ewallet</td>\n",
       "      <td>522.83</td>\n",
       "      <td>4.761905</td>\n",
       "      <td>26.1415</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>226-31-3081</td>\n",
       "      <td>C</td>\n",
       "      <td>Naypyitaw</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Female</td>\n",
       "      <td>Electronic accessories</td>\n",
       "      <td>15.28</td>\n",
       "      <td>5</td>\n",
       "      <td>3.8200</td>\n",
       "      <td>80.2200</td>\n",
       "      <td>3/8/2019</td>\n",
       "      <td>10:29</td>\n",
       "      <td>Cash</td>\n",
       "      <td>76.40</td>\n",
       "      <td>4.761905</td>\n",
       "      <td>3.8200</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>631-41-3108</td>\n",
       "      <td>A</td>\n",
       "      <td>Yangon</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Male</td>\n",
       "      <td>Home and lifestyle</td>\n",
       "      <td>46.33</td>\n",
       "      <td>7</td>\n",
       "      <td>16.2155</td>\n",
       "      <td>340.5255</td>\n",
       "      <td>3/3/2019</td>\n",
       "      <td>13:23</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>324.31</td>\n",
       "      <td>4.761905</td>\n",
       "      <td>16.2155</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>123-19-1176</td>\n",
       "      <td>A</td>\n",
       "      <td>Yangon</td>\n",
       "      <td>Member</td>\n",
       "      <td>Male</td>\n",
       "      <td>Health and beauty</td>\n",
       "      <td>58.22</td>\n",
       "      <td>8</td>\n",
       "      <td>23.2880</td>\n",
       "      <td>489.0480</td>\n",
       "      <td>1/27/2019</td>\n",
       "      <td>20:33</td>\n",
       "      <td>Ewallet</td>\n",
       "      <td>465.76</td>\n",
       "      <td>4.761905</td>\n",
       "      <td>23.2880</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>373-73-7910</td>\n",
       "      <td>A</td>\n",
       "      <td>Yangon</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Male</td>\n",
       "      <td>Sports and travel</td>\n",
       "      <td>86.31</td>\n",
       "      <td>7</td>\n",
       "      <td>30.2085</td>\n",
       "      <td>634.3785</td>\n",
       "      <td>2/8/2019</td>\n",
       "      <td>10:37</td>\n",
       "      <td>Ewallet</td>\n",
       "      <td>604.17</td>\n",
       "      <td>4.761905</td>\n",
       "      <td>30.2085</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Invoice ID Branch       City Customer type  Gender  \\\n",
       "0  750-67-8428      A     Yangon        Member  Female   \n",
       "1  226-31-3081      C  Naypyitaw        Normal  Female   \n",
       "2  631-41-3108      A     Yangon        Normal    Male   \n",
       "3  123-19-1176      A     Yangon        Member    Male   \n",
       "4  373-73-7910      A     Yangon        Normal    Male   \n",
       "\n",
       "             Product line  Unit price  Quantity   Tax 5%     Total       Date  \\\n",
       "0       Health and beauty       74.69         7  26.1415  548.9715   1/5/2019   \n",
       "1  Electronic accessories       15.28         5   3.8200   80.2200   3/8/2019   \n",
       "2      Home and lifestyle       46.33         7  16.2155  340.5255   3/3/2019   \n",
       "3       Health and beauty       58.22         8  23.2880  489.0480  1/27/2019   \n",
       "4       Sports and travel       86.31         7  30.2085  634.3785   2/8/2019   \n",
       "\n",
       "    Time      Payment    cogs  gross margin percentage  gross income  Rating  \n",
       "0  13:08      Ewallet  522.83                 4.761905       26.1415     9.1  \n",
       "1  10:29         Cash   76.40                 4.761905        3.8200     9.6  \n",
       "2  13:23  Credit card  324.31                 4.761905       16.2155     7.4  \n",
       "3  20:33      Ewallet  465.76                 4.761905       23.2880     8.4  \n",
       "4  10:37      Ewallet  604.17                 4.761905       30.2085     5.3  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_transaction= pd.read_csv(\"C:/Users/Win 10/Downloads/supermarket_sales - Sheet1.csv\")\n",
    "data_transaction.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ORDERED DATA\n",
    "* DATA IS AN ORDERED STRING OR NUMERICAL VALUES (Ex: gene code, time series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (0,30) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seqname</th>\n",
       "      <th>source</th>\n",
       "      <th>feature</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>score</th>\n",
       "      <th>strand</th>\n",
       "      <th>frame</th>\n",
       "      <th>CCDS</th>\n",
       "      <th>basic</th>\n",
       "      <th>...</th>\n",
       "      <th>mRNA_start_NF</th>\n",
       "      <th>protein_id</th>\n",
       "      <th>protein_version</th>\n",
       "      <th>seleno</th>\n",
       "      <th>transcript_biotype</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>transcript_name</th>\n",
       "      <th>transcript_source</th>\n",
       "      <th>transcript_support_level</th>\n",
       "      <th>transcript_version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>havana</td>\n",
       "      <td>gene</td>\n",
       "      <td>11869</td>\n",
       "      <td>14409</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>havana</td>\n",
       "      <td>transcript</td>\n",
       "      <td>11869</td>\n",
       "      <td>14409</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>processed_transcript</td>\n",
       "      <td>ENST00000456328</td>\n",
       "      <td>DDX11L1-202</td>\n",
       "      <td>havana</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>havana</td>\n",
       "      <td>exon</td>\n",
       "      <td>11869</td>\n",
       "      <td>12227</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>processed_transcript</td>\n",
       "      <td>ENST00000456328</td>\n",
       "      <td>DDX11L1-202</td>\n",
       "      <td>havana</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>havana</td>\n",
       "      <td>exon</td>\n",
       "      <td>12613</td>\n",
       "      <td>12721</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>processed_transcript</td>\n",
       "      <td>ENST00000456328</td>\n",
       "      <td>DDX11L1-202</td>\n",
       "      <td>havana</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>havana</td>\n",
       "      <td>exon</td>\n",
       "      <td>13221</td>\n",
       "      <td>14409</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>processed_transcript</td>\n",
       "      <td>ENST00000456328</td>\n",
       "      <td>DDX11L1-202</td>\n",
       "      <td>havana</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  seqname  source     feature  start    end score strand frame  CCDS  basic  \\\n",
       "0       1  havana        gene  11869  14409     .      +     .   NaN    NaN   \n",
       "1       1  havana  transcript  11869  14409     .      +     .   NaN    1.0   \n",
       "2       1  havana        exon  11869  12227     .      +     .   NaN    1.0   \n",
       "3       1  havana        exon  12613  12721     .      +     .   NaN    1.0   \n",
       "4       1  havana        exon  13221  14409     .      +     .   NaN    1.0   \n",
       "\n",
       "   ... mRNA_start_NF  protein_id  protein_version seleno  \\\n",
       "0  ...           NaN         NaN              NaN    NaN   \n",
       "1  ...           NaN         NaN              NaN    NaN   \n",
       "2  ...           NaN         NaN              NaN    NaN   \n",
       "3  ...           NaN         NaN              NaN    NaN   \n",
       "4  ...           NaN         NaN              NaN    NaN   \n",
       "\n",
       "     transcript_biotype    transcript_id transcript_name transcript_source  \\\n",
       "0                   NaN              NaN             NaN               NaN   \n",
       "1  processed_transcript  ENST00000456328     DDX11L1-202            havana   \n",
       "2  processed_transcript  ENST00000456328     DDX11L1-202            havana   \n",
       "3  processed_transcript  ENST00000456328     DDX11L1-202            havana   \n",
       "4  processed_transcript  ENST00000456328     DDX11L1-202            havana   \n",
       "\n",
       "  transcript_support_level transcript_version  \n",
       "0                      NaN                NaN  \n",
       "1                        1                2.0  \n",
       "2                        1                2.0  \n",
       "3                        1                2.0  \n",
       "4                        1                2.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gene= pd.read_csv(\"C:/Users/Win 10/Downloads/Homo_sapiens.GRCh38.92.csv\")\n",
    "data_gene.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FREQUENT ITEMSETS AND ASSOCIATION RULES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SET OF RECORDS CONTAINING NUMBER OF ITEMS\n",
    "* TASK: \n",
    "    * INDENTIFY SETS OF ITEMS FREQUENTLY OCCURING TOGETHER\n",
    "    * DEPENDENCY RULES (PREDICTIVE ANALYSICS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLUSTERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SET OF RECORDS CONTAINING ATTRIBUTES AND SIMILARITY MEASURE AMONG THEM\n",
    "* TASK: \n",
    "    * FIND CLUSTERS AMONGST OBJECTS SUCH THAT\n",
    "        * DATA POINTS IN SAME CLUSTER ARE MORE SIMILAR TO EACH OTHER\n",
    "        * DATA POINTS IN SEPARATED CLUSTER ARE LESS SIMILAR TO EACH OTHER\n",
    "* SIMILARITY MEASURE: (FOR QUANTITATIVE VARIABLES) EUCLIDEAN DISTANCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* GIVEN A COLLECTION OF RECORDS, EACH OF THEM HAS MULTIPLE ATTRIBUTES (AT LEAST 1 OF ATTRIBUTES IS CLASS ATTRIBUTE)\n",
    "* DIVIDE THE DATA INTO THE TRAINING SET AND TEST SET\n",
    "* TASK:\n",
    "    * USE THE TRAINING SET TO BUILD A MODEL TO FIND VALUE OF \"CLASS\" BASED ON OTHER ATTRIBUTES\n",
    "    * USE THE TEST SET TO DETERMINE THE ACCURACY OF MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPLORATORY ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TRY TO UNDERSTAND THE DATA AS A PHYSICAL PHENOMENON, CLEARLY DESCRIBE THEM IN SIMPLE METRICS\n",
    "* TASK:\n",
    "    * ASK RIGHT QUESTION AND THOROUGHLY UNDERSTAND THAT QUESTION\n",
    "    * CHOOSE THE RIGHT METRIC TO DESCRIBE, ANSWER QUESTION OR EVEN, BUILD A MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONNECTION OF DATA MINING WITH OTHER FIELD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* DATA MINING IS COMBINATION OF MANY AREA OF SPECIALIZATION\n",
    "    * DATABASE SYSTEM: LARGE-SCALE DATA\n",
    "    * AI (ML): COMPLEX METHOD+ ALGORITHM, SMALL DATA, PATTERN RECOGNITION\n",
    "    * STATISTICS: MODELS, VISUALIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAP-REDUCE PARADIGM\n",
    "\n",
    "* MAP THE DATA INTO KEY-VALUE PAIRS\n",
    "* GROUP BY KEY\n",
    "* REDUCE DATA BY AGGREGATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA ANALYSIS PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. DATA PRE-PROCESSING\n",
    "2. DATA MINING\n",
    "3. RESULT POST-PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA QUALITY\n",
    "* NOISES + OUTLIERS\n",
    "* MISSING VALUES\n",
    "* DUPLICATED DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAMPLING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* KEY PRINCIPLE: SAMPLE IS REPRESENTATIVE OF ENTIRE POPULATION -> NEARLY SAME PROPERTIES OF ENTIRE DATASET\n",
    "\n",
    "* TYPES OF SAMPLING:\n",
    "   * SIMPLE RANDOM SAMPLING: RANDOMLY SELECT PARTICULAR ITEM (SAME PROBA)\n",
    "   * SAMPLING WITHOUT REPLACEMENT: OBJECT IS REMOVED AFTER CHOOSED\n",
    "   * SAMPLING WITH REPLACEMENT: NOT REMOVED\n",
    "   * STRATIFIED SAMPLING: SPLIT THE DATASET INTO SEVERAL PARTITIONS (MAY BE DEPEND ON SPECIFIC CHARACTERISTIC OF ITEMS), THEN DRAW SAMPLE FROM EACH PARTITION."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUMMARY STATISTIC OF DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Random Unsplash Image](https://www.makemyassignments.com/blog/wp-content/uploads/2019/05/Types-of-Descriptive-Statistics.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* FREQUENCY DISTRIBUTION\n",
    "\n",
    "The distribution of the dataset is measured using frequency distribution and is presented in graphical form using a bar chart or a histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MEASURE OF CENTRAL TENDENCY (MEASURE OF LOCATION)\n",
    "\n",
    "The measures of central tendency are used to show the centre of the data set. The central tendency is estimated using the mean, median and mode.\n",
    "\n",
    "Mean is the average of all the data.\n",
    "Median is the middle of the entire data set. Usually, the data is sorted in ascending order and the middle value is considered as the mean. You can use the data analysis option in Microsoft Excel too to determine the median.\n",
    "Mode indicates the most commonly occurring value in the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MEASURE OF SPREAD \n",
    "\n",
    "The objective of measure of dispersion or variation is to identify the extent to which the entire data set is spread from the central tendency – specifically mean.\n",
    "\n",
    "The commonly used estimates are range, standard deviation, and variance.\n",
    "\n",
    "The range is the difference between the maximum and minimum number in the data set.\n",
    "\n",
    "The variance is the square of Standard Deviation. It helps to find the spread of the data. It is different from Standard Deviation which indicates the concentration of data around the mean and uses the same units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEXT MINING STEPS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LOWER CASTING: Converting the text data into lowercase format.\n",
    "* REMOVAL OF PUNCTUATION: Removing a list of punctuations from the text data.\n",
    "* REMOVAL OF STOPWORD: Removing a list of stopwords or commonly occuring words from the text data.\n",
    "* REMOVAL OF FREQUENT WORDS: Removing a list of frequent words in the given corpus from the text data.\n",
    "* STEMMING: Reducing inflected (or sometimes derived) words to their word stem from the text data. For example, stemming two works of does and doing to the suffix of do.\n",
    "* LEMMATIZATION: Reducing inflected words to their word stem from the text data but still saving the root word (also called as lemma) belonging to the language.\n",
    "* REMOVAL OF URLs: Removing any URLs present in the text data.\n",
    "* REMOVAL OF HTML TAGS: Removing any HTML tags present in the text data.\n",
    "* SPELLING CORRECTION: Correcting spelling mistakes in the text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* DIFFERENCE BETWEEN STEMMING AND LEMMATIZATION:\n",
    "    \n",
    "STEM: Stemming words is common NLP technique to reduce topically similar words to their root. For example, “stemming,” “stemmer,” “stemmed,” all have similar meanings; stemming reduces those terms to “stem.”\n",
    "\n",
    "LEMMATIZATION: n many languages, words appear in several inflected forms. For example, in English, the verb ‘to walk’ may appear as ‘walk’, ‘walked’, ‘walks’, ‘walking’. The base form, ‘walk’, that one might look up in a dictionary, is called the lemma for the word. \n",
    "\n",
    "Lemmatisation is closely related to stemming. The difference is that a stemmer operates on a single word without knowledge of the context, and therefore cannot discriminate between words which have different meanings depending on part of speech. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FORMULAS FOR TEXT MINING (DF-TF-IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DF (DOCUMENT FREQUENCY): FRACTION OF DOCUMENTS CONTAINING THE WORDS W\n",
    "\n",
    "    DF(W)= D(W)/D\n",
    "    \n",
    "    D(W): NUMBER OF DOCUMENTS CONTAINING THE WORD W\n",
    "    D: TOTAL NUMBER OF DOCUMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IDF (INVERSE DOCUMENT FREQUENCY): MEASURE OF UNIQUENESS OF THE WORD W\n",
    "    \n",
    "    IDF(W)=LOG(1/DF(W))\n",
    "    \n",
    "    THE HIGHER THE VALUE OF IDF, THE MORE UNIQUE THE WORD TO 1 SPECIFIC DOCUMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF (TERM FREQUENCY): THE FREQUENCY OF THE WORD W IN THE DOCUMENT D\n",
    "  \n",
    "    TF(W,D)= NUMBER OF TIMES THE WORD W APPEAR IN THE DOCUMENT D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF(W,D): MEASURE OF THE IMPORTANCE AND UNIQUENESS OF THE WORD W TO THE DOCUMENT D\n",
    "  \n",
    "    TF-IDF(W,D)=TF(W,D)*IDF(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
