{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING IN TEXT MINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in d:\\anaconda3\\lib\\site-packages (3.0.5)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in d:\\anaconda3\\lib\\site-packages (from spacy) (2.4.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in d:\\anaconda3\\lib\\site-packages (from spacy) (1.19.2)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in d:\\anaconda3\\lib\\site-packages (from spacy) (0.3.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in d:\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in d:\\anaconda3\\lib\\site-packages (from spacy) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda3\\lib\\site-packages (from spacy) (2.11.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in d:\\anaconda3\\lib\\site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda3\\lib\\site-packages (from spacy) (50.3.1.post20201107)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in d:\\anaconda3\\lib\\site-packages (from spacy) (4.50.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in d:\\anaconda3\\lib\\site-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in d:\\anaconda3\\lib\\site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in d:\\anaconda3\\lib\\site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in d:\\anaconda3\\lib\\site-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in d:\\anaconda3\\lib\\site-packages (from spacy) (2.0.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in d:\\anaconda3\\lib\\site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in d:\\anaconda3\\lib\\site-packages (from spacy) (2.24.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.2 in d:\\anaconda3\\lib\\site-packages (from spacy) (8.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda3\\lib\\site-packages (from spacy) (20.4)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in d:\\anaconda3\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in d:\\anaconda3\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in d:\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy) (3.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in d:\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in d:\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: six in d:\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in d:\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user-ag mozilla/4 compat msie window nt avant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beta recreat shipped-local file browser scratc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>moment nscssframeconstructor attributechang ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user-ag mozilla/5 window window nt en-u rv gec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>upload extens wrong min/maxvers lengthi error ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>user-ag mozilla/4 compat msie window nt sv1 ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>user-ag mozilla/5 x11 linux i686 en-gb rv geck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>user-ag mozilla/5 window window nt en-u rv b2 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>user-ag mozilla/5 window window nt en-u rv a1 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>testcas bug cairo build border border-radiu do...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  user-ag mozilla/4 compat msie window nt avant ...\n",
       "1  beta recreat shipped-local file browser scratc...\n",
       "2  moment nscssframeconstructor attributechang ca...\n",
       "3  user-ag mozilla/5 window window nt en-u rv gec...\n",
       "4  upload extens wrong min/maxvers lengthi error ...\n",
       "5  user-ag mozilla/4 compat msie window nt sv1 ne...\n",
       "6  user-ag mozilla/5 x11 linux i686 en-gb rv geck...\n",
       "7  user-ag mozilla/5 window window nt en-u rv b2 ...\n",
       "8  user-ag mozilla/5 window window nt en-u rv a1 ...\n",
       "9  testcas bug cairo build border border-radiu do..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = pd.read_csv(\"C:/Users/Win 10/Downloads/bugtest.csv\", nrows=30)\n",
    "full_df.head()\n",
    "df = full_df[[\"text\"]]\n",
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM 1: LOWER CASTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Converting the text data into lowercase format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    user-ag mozilla/4 compat msie window nt avant ...\n",
       "1    beta recreat shipped-local file browser scratc...\n",
       "2    moment nscssframeconstructor attributechang ca...\n",
       "3    user-ag mozilla/5 window window nt en-u rv gec...\n",
       "4    upload extens wrong min/maxvers lengthi error ...\n",
       "5    user-ag mozilla/4 compat msie window nt sv1 ne...\n",
       "6    user-ag mozilla/5 x11 linux i686 en-gb rv geck...\n",
       "7    user-ag mozilla/5 window window nt en-u rv b2 ...\n",
       "8    user-ag mozilla/5 window window nt en-u rv a1 ...\n",
       "9    testcas bug cairo build border border-radiu do...\n",
       "Name: lowertext, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"lowertext\"] = df[\"text\"].str.lower()\n",
    "df[\"lowertext\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM 2: REMOVAL OF PUNCTUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Removing a list of punctuations from the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNCT = string.punctuation\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('','',PUNCT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    userag mozilla4 compat msie window nt avant br...\n",
       "1    beta recreat shippedlocal file browser scratch...\n",
       "2    moment nscssframeconstructor attributechang ca...\n",
       "3    userag mozilla5 window window nt enu rv gecko2...\n",
       "4    upload extens wrong minmaxvers lengthi error m...\n",
       "5    userag mozilla4 compat msie window nt sv1 net ...\n",
       "6    userag mozilla5 x11 linux i686 engb rv gecko20...\n",
       "7    userag mozilla5 window window nt enu rv b2 gec...\n",
       "8    userag mozilla5 window window nt enu rv a1 gec...\n",
       "9    testcas bug cairo build border borderradiu don...\n",
       "Name: nopuntext, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"nopuntext\"] = df[\"text\"].apply(lambda text: remove_punctuation(text))\n",
    "df[\"nopuntext\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM 3: REMOVAL OF STOPWORD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Removing a list of stopwords or commonly occuring words from the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Win\n",
      "[nltk_data]     10\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    userag mozilla4 compat msie window nt avant br...\n",
       "1    beta recreat shippedlocal file browser scratch...\n",
       "2    moment nscssframeconstructor attributechang ca...\n",
       "3    userag mozilla5 window window nt enu rv gecko2...\n",
       "4    upload extens wrong minmaxvers lengthi error m...\n",
       "5    userag mozilla4 compat msie window nt sv1 net ...\n",
       "6    userag mozilla5 x11 linux i686 engb rv gecko20...\n",
       "7    userag mozilla5 window window nt enu rv b2 gec...\n",
       "8    userag mozilla5 window window nt enu rv a1 gec...\n",
       "9    testcas bug cairo build border borderradiu ren...\n",
       "Name: stopwtext, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We must import NLTK to remove the stopword\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\", \".join(stopwords.words('english'))\n",
    "STOPW = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPW])\n",
    "\n",
    "df[\"stopwtext\"] = df[\"nopuntext\"].apply(lambda text: remove_stopwords(text))\n",
    "df[\"stopwtext\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM 4: REMOVAL OF FREQUENT WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Removing a list of frequent words in the given corpus from the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "for text in df[\"stopwtext\"].values:\n",
    "    for word in text.split():\n",
    "        cnt[word] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt.most_common(10)\n",
    "FREQWS = set([w for (w, wc) in cnt.most_common(10)])\n",
    "def remove_freqwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in FREQWS])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    userag mozilla4 compat msie nt avant browser a...\n",
       "1    beta recreat shippedlocal file browser scratch...\n",
       "2    moment nscssframeconstructor attributechang ca...\n",
       "3    userag mozilla5 nt enu rv gecko20060728 firefo...\n",
       "4    upload extens wrong minmaxvers lengthi error m...\n",
       "5    userag mozilla4 compat msie nt sv1 net clr net...\n",
       "6    userag mozilla5 x11 linux i686 engb rv gecko20...\n",
       "7    userag mozilla5 nt enu rv b2 gecko20060821 fir...\n",
       "8    userag mozilla5 nt enu rv a1 gecko20060808 sea...\n",
       "9    testcas cairo build border borderradiu render ...\n",
       "Name: stopftext, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"stopftext\"] = df[\"stopwtext\"].apply(lambda text: remove_freqwords(text))\n",
    "df[\"stopftext\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM 5: STEMMING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Reducing inflected (or sometimes derived) words to their word stem from the text data. For example,\n",
    "stemming two works of does and doing to the suffix of do.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    userag mozilla4 compat msie nt avant browser a...\n",
       "1    beta recreat shippedloc file browser scratch b...\n",
       "2    moment nscssframeconstructor attributechang ca...\n",
       "3    userag mozilla5 nt enu rv gecko20060728 firefo...\n",
       "4    upload exten wrong minmaxv lengthi error messa...\n",
       "5    userag mozilla4 compat msie nt sv1 net clr net...\n",
       "6    userag mozilla5 x11 linux i686 engb rv gecko20...\n",
       "7    userag mozilla5 nt enu rv b2 gecko20060821 fir...\n",
       "8    userag mozilla5 nt enu rv a1 gecko20060808 sea...\n",
       "9    testca cairo build border borderradiu render b...\n",
       "Name: stemtext, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "df[\"stemtext\"] = df[\"stopftext\"].apply(lambda text: stem_words(text))\n",
    "df[\"stemtext\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM 6: LEMMATIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Reducing inflected words to their word stem from the text data but still saving the root word (also called as lemma) belonging to the language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Win\n",
      "[nltk_data]     10\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_words(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    userag mozilla4 compat msie nt avant browser a...\n",
       "1    beta recreat shippedloc file browser scratch b...\n",
       "2    moment nscssframeconstructor attributechang ca...\n",
       "3    userag mozilla5 nt enu rv gecko20060728 firefo...\n",
       "4    upload exten wrong minmaxv lengthi error messa...\n",
       "5    userag mozilla4 compat msie nt sv1 net clr net...\n",
       "6    userag mozilla5 x11 linux i686 engb rv gecko20...\n",
       "7    userag mozilla5 nt enu rv b2 gecko20060821 fir...\n",
       "8    userag mozilla5 nt enu rv a1 gecko20060808 sea...\n",
       "9    testca cairo build border borderradiu render b...\n",
       "Name: lemtext, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"lemtext\"] = df[\"stemtext\"].apply(lambda text: lemmatize_words(text))\n",
    "df[\"lemtext\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM 7: REMOVAL OF URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Removing any URLs present in the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    userag mozilla4 compat msie nt avant browser a...\n",
       "1    beta recreat shippedloc file browser scratch b...\n",
       "2    moment nscssframeconstructor attributechang ca...\n",
       "3    userag mozilla5 nt enu rv gecko20060728 firefo...\n",
       "4    upload exten wrong minmaxv lengthi error messa...\n",
       "5    userag mozilla4 compat msie nt sv1 net clr net...\n",
       "6    userag mozilla5 x11 linux i686 engb rv gecko20...\n",
       "7    userag mozilla5 nt enu rv b2 gecko20060821 fir...\n",
       "8    userag mozilla5 nt enu rv a1 gecko20060808 sea...\n",
       "9    testca cairo build border borderradiu render b...\n",
       "Name: urltext, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"urltext\"] = df[\"lemtext\"].apply(lambda text: remove_urls(text))\n",
    "df[\"urltext\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM 8: REMOVAL OF HTML TAGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Removing any HTML tags present in the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "def remove_html(text):\n",
    "    return BeautifulSoup(text, \"lxml\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    userag mozilla4 compat msie nt avant browser a...\n",
       "1    beta recreat shippedloc file browser scratch b...\n",
       "2    moment nscssframeconstructor attributechang ca...\n",
       "3    userag mozilla5 nt enu rv gecko20060728 firefo...\n",
       "4    upload exten wrong minmaxv lengthi error messa...\n",
       "5    userag mozilla4 compat msie nt sv1 net clr net...\n",
       "6    userag mozilla5 x11 linux i686 engb rv gecko20...\n",
       "7    userag mozilla5 nt enu rv b2 gecko20060821 fir...\n",
       "8    userag mozilla5 nt enu rv a1 gecko20060808 sea...\n",
       "9    testca cairo build border borderradiu render b...\n",
       "Name: tagtext, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"tagtext\"] = df[\"urltext\"].apply(lambda text: remove_html(text))\n",
    "df[\"tagtext\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM 9: SPELLING CORRECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Correcting spelling mistakes in the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspellchecker\n",
      "  Downloading pyspellchecker-0.6.2-py3-none-any.whl (2.7 MB)\n",
      "Installing collected packages: pyspellchecker\n",
      "Successfully installed pyspellchecker-0.6.2\n"
     ]
    }
   ],
   "source": [
    "! pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "spell = SpellChecker()\n",
    "def correct_spellings(text):\n",
    "    corrected_text = []\n",
    "    misspelled_words = spell.unknown(text.split())\n",
    "    for word in text.split():\n",
    "        if word in misspelled_words:\n",
    "            corrected_text.append(spell.correction(word))\n",
    "        else:\n",
    "            corrected_text.append(word)\n",
    "    return \" \".join(corrected_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    user momzilla combat sie it avant browser avan...\n",
       "1    beta retreat shippedloc file browser scratch b...\n",
       "2    moment nscssframeconstructor attributechang ca...\n",
       "3    user momzilla it end re gecko20060728 firebox ...\n",
       "4    upload eaten wrong minimax length error messag...\n",
       "5    user momzilla combat sie it svu net car net ca...\n",
       "6    user momzilla xu linux i686 eng re gecko200607...\n",
       "7    user momzilla it end re be gecko20060821 fireb...\n",
       "8    user momzilla it end re a gecko20060808 seamon...\n",
       "9    testa cairo build border borderradiu render bo...\n",
       "Name: spelltext, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"spelltext\"] = df[\"tagtext\"].apply(lambda text: correct_spellings(text))\n",
    "df[\"spelltext\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
